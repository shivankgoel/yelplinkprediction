{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from dependencies import *\n",
    "\n",
    "userdata = pd.read_csv('data/yelp/user.csv', low_memory=False)\n",
    "uid2num = {k:v for k,v in zip(userdata['user_id'].values,range(len(userdata['user_id'].values)))}\n",
    "num2uid = {k:v for v,k in uid2num.items()}\n",
    "\n",
    "udata = pickle.load(open( \"udata.p\", \"rb\" ))\n",
    "adj = {uid2num[k]:[uid2num[x] for x in v.split(', ') if x in uid2num] for k,v in zip(udata['user_id'].values,udata['friends'].values)}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "components = pickle.load(open( \"graph_components_apr29.p\", \"rb\" ))\n",
    "#Get the training and the test connected component\n",
    "gc = components[0]\n",
    "\n",
    "def giveagraph(gc,start=0,end=10000):\n",
    "\ttemp = nx.Graph()\n",
    "\ttemp.add_nodes_from(list(gc.nodes)[start:end])\n",
    "\ttemp.add_edges_from([(i,j) for i in temp.nodes for j in gc[i] if j in temp.nodes ])\n",
    "\treturn max(nx.connected_component_subgraphs(temp), key=len)\n",
    "\n",
    "#traing = giveagraph(gc)\n",
    "#testg = giveagraph(gc,10000,20000)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def giveagraph_nodes(gc,nodes):\n",
    "\ttemp = nx.Graph()\n",
    "\ttemp.add_nodes_from(nodes)\n",
    "\ttemp.add_edges_from([(i,j) for i in nodes for j in gc[i] if j in nodes ])\n",
    "\treturn max(nx.connected_component_subgraphs(temp), key=len)\n",
    "\n",
    "import random\n",
    "nodes  = list(gc.nodes)[0:20000]\n",
    "random.Random(4).shuffle(nodes)\n",
    "traing = giveagraph_nodes(gc,nodes[:10000])\n",
    "testg = giveagraph_nodes(gc,nodes[10000:])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7151"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(testg.nodes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample_edges(g,possize=100,negsize=100,full = False):\n",
    "    negexamples = list(nx.non_edges(g))\n",
    "    totaledges = len(g.edges())\n",
    "    if full:\n",
    "        posset = np.array(g.edges())\n",
    "        negsize = totaledges\n",
    "    else:\n",
    "        np.random.seed(4)\n",
    "        posset = np.random.choice(np.array(g.edges()), possize)\n",
    "    np.random.seed(4)\n",
    "    negindices = np.random.choice(range(len(negexamples)), negsize)\n",
    "    negset = np.array(negexamples)[negindices]\n",
    "    return posset,negset\n",
    "\n",
    "postrainset, negtrainset = sample_edges(traing, full = True)\n",
    "postestset, negtestset = sample_edges(testg, full = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "71839"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(postestset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "ids  = udata.to_numpy()[:,[0]]\n",
    "features = udata.to_numpy()[:,[2,4,5,6,7,9,10,11,12,13,14,15,16,17,18,19,20,21]]\n",
    "uid2feat = dict(zip(ids.reshape(-1),features))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "uid2fset = {a:set(b.split(', ')) for a,b in zip(udata['user_id'].values,udata['friends'].values)}\n",
    "uid2bidset = {a:b for a,b in zip(udata['user_id'].values,udata['bidset'].values)}\n",
    "uid2cityset = {a:b for a,b in zip(udata['user_id'].values,udata['cityset'].values)}\n",
    "\n",
    "def givenumcommon(uid2set,uid1,uid2):\n",
    "    a = uid2set[uid1]\n",
    "    b = uid2set[uid2]\n",
    "    return len(a.intersection(b))\n",
    "\n",
    "def givenumunion(uid2set,uid1,uid2):\n",
    "    a = uid2set[uid1]\n",
    "    b = uid2set[uid2]\n",
    "    return len(a.union(b))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def givejaccard(uidset,uid1,uid2):\n",
    "    a = givenumcommon(uidset,uid1,uid2)\n",
    "    b = givenumunion(uidset,uid1,uid2)\n",
    "    return np.round((a*1.0)/(b*1.0),2)\n",
    "\n",
    "def giveprefattach(uid2set,uid1,uid2):\n",
    "    a = uid2set[uid1]\n",
    "    b = uid2set[uid2]\n",
    "    return (len(a) * len(b))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def giveedgefeats(pairlist,cfriends=True,cbids=True,ccities= True):\n",
    "    X = []\n",
    "    for p in pairlist:\n",
    "        id0 = num2uid[p[0]]\n",
    "        id1 = num2uid[p[1]]\n",
    "        feats = []\n",
    "        if cfriends:\n",
    "            feats.append(givenumcommon(uid2fset,id0,id1))\n",
    "        if cbids:\n",
    "            feats.append(givenumcommon(uid2bidset,id0,id1))\n",
    "        if ccities:\n",
    "            feats.append(givenumcommon(uid2cityset,id0,id1))\n",
    "        X.append(feats)\n",
    "    return np.array(X)\n",
    "\n",
    "def giveedgefeats_jaccard(pairlist):\n",
    "    X = []\n",
    "    for p in pairlist:\n",
    "        id0 = num2uid[p[0]]\n",
    "        id1 = num2uid[p[1]]\n",
    "        feats = []\n",
    "        feats.append(givejaccard(uid2fset,id0,id1))\n",
    "        feats.append(givejaccard(uid2bidset,id0,id1))\n",
    "        feats.append(givejaccard(uid2cityset,id0,id1))\n",
    "        X.append(feats)\n",
    "    return np.array(X)\n",
    "\n",
    "def giveedgefeats_prefattach(pairlist):\n",
    "    X = []\n",
    "    for p in pairlist:\n",
    "        id0 = num2uid[p[0]]\n",
    "        id1 = num2uid[p[1]]\n",
    "        feats = []\n",
    "        feats.append(giveprefattach(uid2fset,id0,id1))\n",
    "        feats.append(giveprefattach(uid2bidset,id0,id1))\n",
    "        feats.append(giveprefattach(uid2cityset,id0,id1))\n",
    "        X.append(feats)\n",
    "    return np.array(X)\n",
    "\n",
    "def giveedgefeats_all(pairlist):\n",
    "    X = []\n",
    "    for p in pairlist:\n",
    "        id0 = num2uid[p[0]]\n",
    "        id1 = num2uid[p[1]]\n",
    "        feats = []\n",
    "        feats.append(givenumcommon(uid2fset,id0,id1))\n",
    "        feats.append(givenumcommon(uid2bidset,id0,id1))\n",
    "        feats.append(givenumcommon(uid2cityset,id0,id1))\n",
    "        feats.append(givejaccard(uid2fset,id0,id1))\n",
    "        feats.append(givejaccard(uid2bidset,id0,id1))\n",
    "        feats.append(givejaccard(uid2cityset,id0,id1))\n",
    "        X.append(feats)\n",
    "    return np.array(X)\n",
    "\n",
    "def giveedgedata(posset,negset,cfriends=True,cbids=True,ccities= True):\n",
    "    X1  = giveedgefeats(posset,cfriends,cbids,ccities)\n",
    "    X2  = giveedgefeats(negset,cfriends,cbids,ccities)\n",
    "    X = np.concatenate((X1,X2),0)\n",
    "    y = np.concatenate((np.ones((X1.shape[0],1)),np.zeros((X2.shape[0],1))),0)\n",
    "    X,y = shuffle(X,y)\n",
    "    return X,y\n",
    "\n",
    "def giveedgedata_jaccard(posset,negset):\n",
    "    X1  = giveedgefeats_jaccard(posset)\n",
    "    X2  = giveedgefeats_jaccard(negset)\n",
    "    X = np.concatenate((X1,X2),0)\n",
    "    y = np.concatenate((np.ones((X1.shape[0],1)),np.zeros((X2.shape[0],1))),0)\n",
    "    X,y = shuffle(X,y)\n",
    "    return X,y\n",
    "\n",
    "def giveedgedata_prefattach(posset,negset):\n",
    "    X1  = giveedgefeats_prefattach(posset)\n",
    "    X2  = giveedgefeats_prefattach(negset)\n",
    "    X = np.concatenate((X1,X2),0)\n",
    "    y = np.concatenate((np.ones((X1.shape[0],1)),np.zeros((X2.shape[0],1))),0)\n",
    "    X,y = shuffle(X,y)\n",
    "    return X,y\n",
    "\n",
    "\n",
    "def giveedgedata_all(posset,negset):\n",
    "    X1  = giveedgefeats_all(posset)\n",
    "    X2  = giveedgefeats_all(negset)\n",
    "    X = np.concatenate((X1,X2),0)\n",
    "    y = np.concatenate((np.ones((X1.shape[0],1)),np.zeros((X2.shape[0],1))),0)\n",
    "    X,y = shuffle(X,y)\n",
    "    return X,y\n",
    "\n",
    "def givenodefeats(pairlist):\n",
    "    X = []\n",
    "    for p in pairlist:\n",
    "        id0 = num2uid[p[0]]\n",
    "        id1 = num2uid[p[1]]\n",
    "        X.append(np.concatenate([uid2feat[id0], uid2feat[id1]]))\n",
    "    return np.array(X)\n",
    "\n",
    "def givenodedata(posset,negset):\n",
    "    X1  = givenodefeats(posset)\n",
    "    X2  = givenodefeats(negset)\n",
    "    X = np.concatenate((X1,X2),0)\n",
    "    y = np.concatenate((np.ones((X1.shape[0],1)),np.zeros((X2.shape[0],1))),0)\n",
    "    X,y = shuffle(X,y)\n",
    "    return X,y\n",
    "\n",
    "\n",
    "def givedatausingbothfeats(posset,negset):\n",
    "    X1  = np.concatenate((giveedgefeats(posset),givenodefeats(posset)),1)\n",
    "    X2  = np.concatenate((giveedgefeats(negset),givenodefeats(negset)),1)\n",
    "    X = np.concatenate((X1,X2),0)\n",
    "    y = np.concatenate((np.ones((X1.shape[0],1)),np.zeros((X2.shape[0],1))),0)\n",
    "    X,y = shuffle(X,y)\n",
    "    return X,y\n",
    "\n",
    "\n",
    "def givedatausingbothfeats_jaccard(posset,negset):\n",
    "    X1  = np.concatenate((giveedgefeats_jaccard(posset),givenodefeats(posset)),1)\n",
    "    X2  = np.concatenate((giveedgefeats_jaccard(negset),givenodefeats(negset)),1)\n",
    "    X = np.concatenate((X1,X2),0)\n",
    "    y = np.concatenate((np.ones((X1.shape[0],1)),np.zeros((X2.shape[0],1))),0)\n",
    "    X,y = shuffle(X,y)\n",
    "    return X,y\n",
    "\n",
    "def givefeats(pairlist):\n",
    "    X = []\n",
    "    for p in pairlist:\n",
    "        id0 = p[0]\n",
    "        id1 = p[1]\n",
    "        X.append([id0,id1])\n",
    "    return np.array(X)\n",
    "    \n",
    "def givedata(posset,negset):\n",
    "    X1  = givefeats(posset)\n",
    "    X2  = givefeats(negset)\n",
    "    X = np.concatenate((X1,X2),0)\n",
    "    y = np.concatenate((np.ones((X1.shape[0],1)),np.zeros((X2.shape[0],1))),0)\n",
    "    X,y = shuffle(X,y)\n",
    "    return X,y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def giveresults(Ytest,ytestpred):\n",
    "    print(\"Accuracy \",np.round(accuracy_score(Ytest,ytestpred),3))\n",
    "    print(\"Precision \",np.round(precision_score(Ytest,ytestpred),3))\n",
    "    print(\"Recall \",np.round(recall_score(Ytest,ytestpred),3))\n",
    "    print(\"F1 Score \",np.round(f1_score(Ytest,ytestpred),3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['KMP_DUPLICATE_LIB_OK']='True'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "\n",
    "from numpy.random import seed\n",
    "seed(3)\n",
    "from tensorflow import set_random_seed\n",
    "set_random_seed(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.nn import init\n",
    "import torch.nn.functional as F\n",
    "from torch.autograd import Variable\n",
    "import random\n",
    "random.seed(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Encoder(nn.Module):\n",
    "    \"\"\"\n",
    "    Encodes a node's using 'convolutional' GraphSage approach\n",
    "    \"\"\"\n",
    "    def __init__(self, features, feature_dim, embed_dim, adj_lists, aggregator, n2mat, num_sample=10, base_model=None): \n",
    "        super(Encoder, self).__init__()\n",
    "        self.features = features\n",
    "        self.feat_dim = feature_dim\n",
    "        self.adj_lists = adj_lists\n",
    "        self.aggregator = aggregator\n",
    "        self.num_sample = num_sample\n",
    "        if base_model != None:\n",
    "            self.base_model = base_model\n",
    "        self.embed_dim = embed_dim\n",
    "        self.weight = nn.Parameter(torch.FloatTensor(embed_dim, 2 * self.feat_dim))\n",
    "        init.xavier_uniform_(self.weight)\n",
    "        self.n2mat = n2mat\n",
    "    def forward(self, nodes):\n",
    "        \"\"\"\n",
    "        Generates embeddings for a batch of nodes.\n",
    "        nodes     -- list of nodes\n",
    "        \"\"\"\n",
    "        #print(self)\n",
    "        neigh_feats = self.aggregator.forward(nodes, [set(self.adj_lists[int(node)]) for node in nodes], self.num_sample)\n",
    "        #self_feats = self.features(torch.LongTensor([self.n2mat[x] for x in nodes]))\n",
    "        self_feats = self.features[[self.n2mat[x] for x in nodes]]\n",
    "        combined = torch.cat([self_feats, neigh_feats], dim=1)\n",
    "        combined = F.relu(self.weight.mm(combined.t()))\n",
    "        return combined"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MeanAggregator(nn.Module):\n",
    "    \"\"\"\n",
    "    Aggregates a node's embeddings using mean of neighbors' embeddings\n",
    "    \"\"\"\n",
    "    def __init__(self, features,n2mat): \n",
    "        super(MeanAggregator, self).__init__()\n",
    "        self.features = features\n",
    "        self.n2mat = n2mat\n",
    "        \n",
    "    def forward(self, nodes, to_neighs, num_sample=10):\n",
    "        \"\"\"\n",
    "        nodes --- list of nodes in a batch\n",
    "        to_neighs --- list of sets, each set is the set of neighbors for node in batch\n",
    "        num_sample --- number of neighbors to sample. No sampling if None.\n",
    "        \"\"\"\n",
    "        # Local pointers to functions (speed hack)\n",
    "        #print(self)\n",
    "        _set = set\n",
    "        samp_neighs = to_neighs    \n",
    "        unique_nodes_list = list(set.union(*samp_neighs))\n",
    "        unique_nodes = {n:i for i,n in enumerate(unique_nodes_list)}\n",
    "        mask = Variable(torch.zeros(len(samp_neighs), len(unique_nodes)))\n",
    "        column_indices = [unique_nodes[n] for samp_neigh in samp_neighs for n in samp_neigh]   \n",
    "        row_indices = [i for i in range(len(samp_neighs)) for j in range(len(samp_neighs[i]))]\n",
    "        mask[row_indices, column_indices] = 1\n",
    "        num_neigh = mask.sum(1, keepdim=True)\n",
    "        mask = mask.div(num_neigh)\n",
    "        #embed_matrix = self.features(torch.LongTensor([self.n2mat[x] for x in unique_nodes_list]))\n",
    "        embed_matrix = self.features[[self.n2mat[x] for x in unique_nodes_list]]\n",
    "        to_feats = mask.mm(embed_matrix)\n",
    "        return to_feats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SupervisedGraphSage(nn.Module):\n",
    "\n",
    "    def __init__(self, enc):\n",
    "        super(SupervisedGraphSage, self).__init__()\n",
    "        self.enc = enc\n",
    "        self.fc1 = nn.Linear(2*enc.embed_dim,24)\n",
    "        self.fc2 = nn.Linear(24,16)\n",
    "        self.fc3 = nn.Linear(16,2)\n",
    "    def forward(self, nodes,test=False):\n",
    "        self.enc = updateenc(self.enc,test)\n",
    "        embeds1 = self.enc(nodes[:,0])\n",
    "        embeds2 = self.enc(nodes[:,1])\n",
    "        embeds = torch.cat([embeds1, embeds2], dim=0)\n",
    "        hidden1 = F.relu(self.fc1(embeds.t()))\n",
    "        hidden2 = F.relu(self.fc2(hidden1))\n",
    "        return self.fc3(hidden2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def updateenc(enc,test=False):\n",
    "    enc.features = enc1(nodes).t()\n",
    "    enc.aggregator.features = enc1(nodes).t()\n",
    "    return enc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "ttg = nx.Graph()\n",
    "ttg.add_edges_from(list(traing.edges(data=True))+list(testg.edges(data=True)))\n",
    "ttg.add_nodes_from(list(traing.nodes(data=True))+list(testg.nodes(data=True)))\n",
    "feat_data = np.array([uid2feat[num2uid[x]] for x in ttg]).astype(dtype = 'float32')\n",
    "nodes = list(ttg.nodes())\n",
    "testnodes = list(testg.nodes())\n",
    "trainnodes = list(traing.nodes())\n",
    "n2mat = {i:j for j,i in enumerate(ttg.nodes)}\n",
    "mat2n = {i:j for j,i in n2mat.items()}\n",
    "features = torch.FloatTensor(feat_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "agg1 = MeanAggregator(features,n2mat)\n",
    "enc1 = Encoder(features, 18, 15, ttg, agg1,n2mat)\n",
    "agg2 = MeanAggregator(enc1(nodes).t(), n2mat)\n",
    "enc2 = Encoder(enc1(nodes).t(), 15, 15, ttg, agg2,n2mat, base_model=enc1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 tensor(86.3487)\n",
      "5 tensor(30.0581)\n",
      "10 tensor(13.5879)\n",
      "15 tensor(7.4119)\n",
      "20 tensor(3.1574)\n",
      "25 tensor(2.6200)\n",
      "30 tensor(2.6951)\n",
      "35 tensor(1.9687)\n",
      "40 tensor(3.9672)\n",
      "45 tensor(1.9114)\n",
      "50 tensor(1.4784)\n",
      "55 tensor(1.6750)\n",
      "60 tensor(3.2879)\n",
      "65 tensor(1.2400)\n",
      "70 tensor(1.3324)\n",
      "75 tensor(1.5246)\n",
      "80 tensor(0.8865)\n",
      "85 tensor(1.0063)\n",
      "90 tensor(1.9248)\n",
      "95 tensor(0.8662)\n",
      "100 tensor(1.2226)\n",
      "105 tensor(1.0177)\n",
      "110 tensor(1.3139)\n",
      "115 tensor(1.2134)\n",
      "120 tensor(1.3767)\n",
      "125 tensor(0.7284)\n",
      "130 tensor(1.1222)\n",
      "135 tensor(0.7570)\n",
      "140 tensor(1.5308)\n",
      "145 tensor(0.8694)\n",
      "150 tensor(1.5971)\n",
      "155 tensor(0.7454)\n",
      "160 tensor(0.8079)\n",
      "165 tensor(0.8381)\n",
      "170 tensor(1.7374)\n",
      "175 tensor(0.7759)\n",
      "180 tensor(0.9990)\n",
      "185 tensor(0.8890)\n",
      "190 tensor(1.0059)\n",
      "195 tensor(1.0471)\n"
     ]
    }
   ],
   "source": [
    "graphsage = SupervisedGraphSage(enc2)\n",
    "x,y = givedata(postrainset,negtrainset)\n",
    "xtest,ytest = givedata(postestset,negtestset)\n",
    "\n",
    "optimizer = torch.optim.Adam(filter(lambda p : p.requires_grad, graphsage.parameters()))\n",
    "times = []\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "for batch in range(200):\n",
    "    batch_x = x[:100]\n",
    "    batch_y = y[:100]\n",
    "    x,y = shuffle(x,y)\n",
    "    optimizer.zero_grad()\n",
    "    loss = criterion(graphsage(batch_x),Variable(torch.LongTensor(batch_y)).squeeze())\n",
    "    loss.backward(retain_graph=True)\n",
    "    optimizer.step()\n",
    "    if batch %5 == 0:\n",
    "        print(batch, loss.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy  0.798\n",
      "Precision  0.82\n",
      "Recall  0.785\n",
      "F1 Score  0.802\n"
     ]
    }
   ],
   "source": [
    "test_out = graphsage(xtest)\n",
    "ypred = test_out.data.numpy().argmax(axis=1)\n",
    "giveresults(ypred,ytest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 tensor(15.7374)\n",
      "5 tensor(3.0723)\n",
      "10 tensor(4.5044)\n",
      "15 tensor(1.8453)\n",
      "20 tensor(1.3481)\n",
      "25 tensor(0.9711)\n",
      "30 tensor(1.0735)\n",
      "35 tensor(0.8853)\n",
      "40 tensor(0.6843)\n",
      "45 tensor(0.7821)\n",
      "50 tensor(0.5955)\n",
      "55 tensor(1.4429)\n",
      "60 tensor(0.6454)\n",
      "65 tensor(0.5792)\n",
      "70 tensor(0.8554)\n",
      "75 tensor(0.5048)\n",
      "80 tensor(0.5289)\n",
      "85 tensor(0.4728)\n",
      "90 tensor(0.4753)\n",
      "95 tensor(0.7044)\n",
      "100 tensor(0.8138)\n",
      "105 tensor(0.5685)\n",
      "110 tensor(1.4891)\n",
      "115 tensor(0.5563)\n",
      "120 tensor(1.9567)\n",
      "125 tensor(0.5070)\n",
      "130 tensor(0.4967)\n",
      "135 tensor(0.5194)\n",
      "140 tensor(0.5541)\n",
      "145 tensor(0.4319)\n",
      "150 tensor(0.4304)\n",
      "155 tensor(1.3842)\n",
      "160 tensor(0.3311)\n",
      "165 tensor(0.3795)\n",
      "170 tensor(0.4387)\n",
      "175 tensor(0.3771)\n",
      "180 tensor(0.3511)\n",
      "185 tensor(0.4045)\n",
      "190 tensor(0.4226)\n",
      "195 tensor(0.4796)\n",
      "Accuracy  0.801\n",
      "Precision  0.806\n",
      "Recall  0.798\n",
      "F1 Score  0.802\n"
     ]
    }
   ],
   "source": [
    "agg1 = MeanAggregator(features,n2mat)\n",
    "enc1 = Encoder(features, 18, 16, ttg, agg1,n2mat)\n",
    "agg2 = MeanAggregator(enc1(nodes).t(), n2mat)\n",
    "enc2 = Encoder(enc1(nodes).t(), 16, 16, ttg, agg2,n2mat, base_model=enc1)\n",
    "\n",
    "graphsage = SupervisedGraphSage(enc2)\n",
    "\n",
    "optimizer = torch.optim.Adam(filter(lambda p : p.requires_grad, graphsage.parameters()))\n",
    "times = []\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "for batch in range(200):\n",
    "    batch_x = x[:100]\n",
    "    batch_y = y[:100]\n",
    "    x,y = shuffle(x,y)\n",
    "    optimizer.zero_grad()\n",
    "    loss = criterion(graphsage(batch_x),Variable(torch.LongTensor(batch_y)).squeeze())\n",
    "    loss.backward(retain_graph=True)\n",
    "    optimizer.step()\n",
    "    if batch %5 == 0:\n",
    "        print(batch, loss.data)\n",
    "\n",
    "        \n",
    "test_out = graphsage(xtest)\n",
    "ypred = test_out.data.numpy().argmax(axis=1)\n",
    "giveresults(ypred,ytest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 tensor(23.3287)\n",
      "5 tensor(13.8694)\n",
      "10 tensor(3.7746)\n",
      "15 tensor(1.9770)\n",
      "20 tensor(3.3500)\n",
      "25 tensor(3.6127)\n",
      "30 tensor(1.6593)\n",
      "35 tensor(1.4157)\n",
      "40 tensor(3.0206)\n",
      "45 tensor(1.4091)\n",
      "50 tensor(1.7368)\n",
      "55 tensor(1.5746)\n",
      "60 tensor(1.2395)\n",
      "65 tensor(2.0416)\n",
      "70 tensor(1.8512)\n",
      "75 tensor(1.1583)\n",
      "80 tensor(1.6145)\n",
      "85 tensor(1.3043)\n",
      "90 tensor(2.1656)\n",
      "95 tensor(1.4310)\n",
      "100 tensor(1.2941)\n",
      "105 tensor(0.6223)\n",
      "110 tensor(1.9811)\n",
      "115 tensor(1.1620)\n",
      "120 tensor(0.6461)\n",
      "125 tensor(0.5776)\n",
      "130 tensor(0.6812)\n",
      "135 tensor(0.4866)\n",
      "140 tensor(0.8487)\n",
      "145 tensor(1.2366)\n",
      "150 tensor(1.1712)\n",
      "155 tensor(0.7333)\n",
      "160 tensor(1.1156)\n",
      "165 tensor(0.8406)\n",
      "170 tensor(0.7784)\n",
      "175 tensor(0.5833)\n",
      "180 tensor(0.5927)\n",
      "185 tensor(0.8451)\n",
      "190 tensor(0.7322)\n",
      "195 tensor(1.4686)\n",
      "Accuracy  0.771\n",
      "Precision  0.659\n",
      "Recall  0.85\n",
      "F1 Score  0.743\n"
     ]
    }
   ],
   "source": [
    "agg1 = MeanAggregator(features,n2mat)\n",
    "enc1 = Encoder(features, 18, 17, ttg, agg1,n2mat)\n",
    "agg2 = MeanAggregator(enc1(nodes).t(), n2mat)\n",
    "enc2 = Encoder(enc1(nodes).t(), 17, 17, ttg, agg2,n2mat, base_model=enc1)\n",
    "\n",
    "graphsage = SupervisedGraphSage(enc2)\n",
    "\n",
    "optimizer = torch.optim.Adam(filter(lambda p : p.requires_grad, graphsage.parameters()))\n",
    "times = []\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "for batch in range(200):\n",
    "    batch_x = x[:100]\n",
    "    batch_y = y[:100]\n",
    "    x,y = shuffle(x,y)\n",
    "    optimizer.zero_grad()\n",
    "    loss = criterion(graphsage(batch_x),Variable(torch.LongTensor(batch_y)).squeeze())\n",
    "    loss.backward(retain_graph=True)\n",
    "    optimizer.step()\n",
    "    if batch %5 == 0:\n",
    "        print(batch, loss.data)\n",
    "\n",
    "        \n",
    "test_out = graphsage(xtest)\n",
    "ypred = test_out.data.numpy().argmax(axis=1)\n",
    "giveresults(ypred,ytest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 tensor(22.3008)\n",
      "5 tensor(5.8400)\n",
      "10 tensor(3.7118)\n",
      "15 tensor(2.3068)\n",
      "20 tensor(2.8552)\n",
      "25 tensor(1.7214)\n",
      "30 tensor(1.5696)\n",
      "35 tensor(2.5285)\n",
      "40 tensor(1.4434)\n",
      "45 tensor(1.2077)\n",
      "50 tensor(0.8592)\n",
      "55 tensor(2.2622)\n",
      "60 tensor(1.2286)\n",
      "65 tensor(1.8804)\n",
      "70 tensor(1.4293)\n",
      "75 tensor(1.1950)\n",
      "80 tensor(0.9521)\n",
      "85 tensor(1.5891)\n",
      "90 tensor(0.6407)\n",
      "95 tensor(1.2950)\n",
      "100 tensor(1.0272)\n",
      "105 tensor(1.3650)\n",
      "110 tensor(0.7259)\n",
      "115 tensor(0.6592)\n",
      "120 tensor(0.8545)\n",
      "125 tensor(0.8853)\n",
      "130 tensor(0.9143)\n",
      "135 tensor(0.5148)\n",
      "140 tensor(0.5824)\n",
      "145 tensor(0.4627)\n",
      "150 tensor(0.6248)\n",
      "155 tensor(0.8397)\n",
      "160 tensor(0.6271)\n",
      "165 tensor(0.7166)\n",
      "170 tensor(0.5127)\n",
      "175 tensor(0.7075)\n",
      "180 tensor(1.0024)\n",
      "185 tensor(0.7469)\n",
      "190 tensor(0.9249)\n",
      "195 tensor(0.5778)\n",
      "Accuracy  0.789\n",
      "Precision  0.717\n",
      "Recall  0.837\n",
      "F1 Score  0.772\n"
     ]
    }
   ],
   "source": [
    "agg1 = MeanAggregator(features,n2mat)\n",
    "enc1 = Encoder(features, 18, 18, ttg, agg1,n2mat)\n",
    "agg2 = MeanAggregator(enc1(nodes).t(), n2mat)\n",
    "enc2 = Encoder(enc1(nodes).t(), 18, 18, ttg, agg2,n2mat, base_model=enc1)\n",
    "\n",
    "graphsage = SupervisedGraphSage(enc2)\n",
    "\n",
    "optimizer = torch.optim.Adam(filter(lambda p : p.requires_grad, graphsage.parameters()))\n",
    "times = []\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "for batch in range(200):\n",
    "    batch_x = x[:100]\n",
    "    batch_y = y[:100]\n",
    "    x,y = shuffle(x,y)\n",
    "    optimizer.zero_grad()\n",
    "    loss = criterion(graphsage(batch_x),Variable(torch.LongTensor(batch_y)).squeeze())\n",
    "    loss.backward(retain_graph=True)\n",
    "    optimizer.step()\n",
    "    if batch %5 == 0:\n",
    "        print(batch, loss.data)\n",
    "\n",
    "        \n",
    "test_out = graphsage(xtest)\n",
    "ypred = test_out.data.numpy().argmax(axis=1)\n",
    "giveresults(ypred,ytest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 tensor(131.9749)\n",
      "5 tensor(21.5338)\n",
      "10 tensor(12.5915)\n",
      "15 tensor(12.8721)\n",
      "20 tensor(5.1118)\n",
      "25 tensor(4.2291)\n",
      "30 tensor(5.0770)\n",
      "35 tensor(2.1741)\n",
      "40 tensor(1.7479)\n",
      "45 tensor(1.3906)\n",
      "50 tensor(2.4856)\n",
      "55 tensor(3.8061)\n",
      "60 tensor(1.4532)\n",
      "65 tensor(1.0547)\n",
      "70 tensor(1.5311)\n",
      "75 tensor(2.6240)\n",
      "80 tensor(1.7206)\n",
      "85 tensor(1.8064)\n",
      "90 tensor(2.2836)\n",
      "95 tensor(3.2060)\n",
      "100 tensor(1.2405)\n",
      "105 tensor(0.2966)\n",
      "110 tensor(1.3272)\n",
      "115 tensor(0.9778)\n",
      "120 tensor(0.9812)\n",
      "125 tensor(1.1760)\n",
      "130 tensor(1.0163)\n",
      "135 tensor(1.1990)\n",
      "140 tensor(4.2620)\n",
      "145 tensor(1.7355)\n",
      "150 tensor(1.6201)\n",
      "155 tensor(1.3860)\n",
      "160 tensor(0.9423)\n",
      "165 tensor(1.0385)\n",
      "170 tensor(1.1260)\n",
      "175 tensor(0.8766)\n",
      "180 tensor(1.3247)\n",
      "185 tensor(0.8330)\n",
      "190 tensor(1.7259)\n",
      "195 tensor(1.8095)\n",
      "Accuracy  0.773\n",
      "Precision  0.728\n",
      "Recall  0.8\n",
      "F1 Score  0.762\n"
     ]
    }
   ],
   "source": [
    "agg1 = MeanAggregator(features,n2mat)\n",
    "enc1 = Encoder(features, 18, 14, ttg, agg1,n2mat)\n",
    "agg2 = MeanAggregator(enc1(nodes).t(), n2mat)\n",
    "enc2 = Encoder(enc1(nodes).t(), 14, 14, ttg, agg2,n2mat, base_model=enc1)\n",
    "\n",
    "graphsage = SupervisedGraphSage(enc2)\n",
    "\n",
    "optimizer = torch.optim.Adam(filter(lambda p : p.requires_grad, graphsage.parameters()))\n",
    "times = []\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "for batch in range(200):\n",
    "    batch_x = x[:100]\n",
    "    batch_y = y[:100]\n",
    "    x,y = shuffle(x,y)\n",
    "    optimizer.zero_grad()\n",
    "    loss = criterion(graphsage(batch_x),Variable(torch.LongTensor(batch_y)).squeeze())\n",
    "    loss.backward(retain_graph=True)\n",
    "    optimizer.step()\n",
    "    if batch %5 == 0:\n",
    "        print(batch, loss.data)\n",
    "\n",
    "        \n",
    "test_out = graphsage(xtest)\n",
    "ypred = test_out.data.numpy().argmax(axis=1)\n",
    "giveresults(ypred,ytest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 tensor(55.3798)\n",
      "5 tensor(36.0598)\n",
      "10 tensor(19.1607)\n",
      "15 tensor(9.7822)\n",
      "20 tensor(9.4688)\n",
      "25 tensor(6.9039)\n",
      "30 tensor(5.4749)\n",
      "35 tensor(2.6725)\n",
      "40 tensor(3.6655)\n",
      "45 tensor(2.6457)\n",
      "50 tensor(2.2779)\n",
      "55 tensor(2.3858)\n",
      "60 tensor(1.6467)\n",
      "65 tensor(1.0703)\n",
      "70 tensor(1.8564)\n",
      "75 tensor(1.9564)\n",
      "80 tensor(2.2379)\n",
      "85 tensor(1.5368)\n",
      "90 tensor(2.2814)\n",
      "95 tensor(1.2444)\n",
      "100 tensor(1.0745)\n",
      "105 tensor(1.8506)\n",
      "110 tensor(2.5439)\n",
      "115 tensor(1.5598)\n",
      "120 tensor(0.7249)\n",
      "125 tensor(1.1119)\n",
      "130 tensor(0.7100)\n",
      "135 tensor(0.5431)\n",
      "140 tensor(2.5515)\n",
      "145 tensor(0.9427)\n",
      "150 tensor(1.5771)\n",
      "155 tensor(1.1630)\n",
      "160 tensor(1.0455)\n",
      "165 tensor(0.7609)\n",
      "170 tensor(1.1321)\n",
      "175 tensor(0.9875)\n",
      "180 tensor(0.8095)\n",
      "185 tensor(0.5528)\n",
      "190 tensor(0.7781)\n",
      "195 tensor(0.8552)\n",
      "Accuracy  0.757\n",
      "Precision  0.873\n",
      "Recall  0.708\n",
      "F1 Score  0.782\n"
     ]
    }
   ],
   "source": [
    "agg1 = MeanAggregator(features,n2mat)\n",
    "enc1 = Encoder(features, 18, 13, ttg, agg1,n2mat)\n",
    "agg2 = MeanAggregator(enc1(nodes).t(), n2mat)\n",
    "enc2 = Encoder(enc1(nodes).t(), 13, 13, ttg, agg2,n2mat, base_model=enc1)\n",
    "\n",
    "graphsage = SupervisedGraphSage(enc2)\n",
    "\n",
    "optimizer = torch.optim.Adam(filter(lambda p : p.requires_grad, graphsage.parameters()))\n",
    "times = []\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "for batch in range(200):\n",
    "    batch_x = x[:100]\n",
    "    batch_y = y[:100]\n",
    "    x,y = shuffle(x,y)\n",
    "    optimizer.zero_grad()\n",
    "    loss = criterion(graphsage(batch_x),Variable(torch.LongTensor(batch_y)).squeeze())\n",
    "    loss.backward(retain_graph=True)\n",
    "    optimizer.step()\n",
    "    if batch %5 == 0:\n",
    "        print(batch, loss.data)\n",
    "\n",
    "        \n",
    "test_out = graphsage(xtest)\n",
    "ypred = test_out.data.numpy().argmax(axis=1)\n",
    "giveresults(ypred,ytest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 tensor(19.5582)\n",
      "5 tensor(13.2077)\n",
      "10 tensor(5.8570)\n",
      "15 tensor(4.2053)\n",
      "20 tensor(2.8801)\n",
      "25 tensor(2.7962)\n",
      "30 tensor(2.7676)\n",
      "35 tensor(3.6003)\n",
      "40 tensor(2.1711)\n",
      "45 tensor(2.3089)\n",
      "50 tensor(2.1443)\n",
      "55 tensor(3.2787)\n",
      "60 tensor(1.9635)\n",
      "65 tensor(1.8828)\n",
      "70 tensor(0.9320)\n",
      "75 tensor(1.2480)\n",
      "80 tensor(1.0462)\n",
      "85 tensor(0.7324)\n",
      "90 tensor(2.7540)\n",
      "95 tensor(1.0083)\n",
      "100 tensor(1.0115)\n",
      "105 tensor(1.7019)\n",
      "110 tensor(0.7791)\n",
      "115 tensor(1.1974)\n",
      "120 tensor(1.9402)\n",
      "125 tensor(1.0576)\n",
      "130 tensor(1.2715)\n",
      "135 tensor(1.1942)\n",
      "140 tensor(1.0393)\n",
      "145 tensor(0.6401)\n",
      "150 tensor(1.7123)\n",
      "155 tensor(0.9950)\n",
      "160 tensor(0.7063)\n",
      "165 tensor(1.0313)\n",
      "170 tensor(1.0632)\n",
      "175 tensor(0.4776)\n",
      "180 tensor(0.9114)\n",
      "185 tensor(0.8035)\n",
      "190 tensor(0.7696)\n",
      "195 tensor(0.9471)\n",
      "Accuracy  0.755\n",
      "Precision  0.856\n",
      "Recall  0.712\n",
      "F1 Score  0.777\n"
     ]
    }
   ],
   "source": [
    "agg1 = MeanAggregator(features,n2mat)\n",
    "enc1 = Encoder(features, 18, 12, ttg, agg1,n2mat)\n",
    "agg2 = MeanAggregator(enc1(nodes).t(), n2mat)\n",
    "enc2 = Encoder(enc1(nodes).t(), 12, 12, ttg, agg2,n2mat, base_model=enc1)\n",
    "\n",
    "graphsage = SupervisedGraphSage(enc2)\n",
    "\n",
    "optimizer = torch.optim.Adam(filter(lambda p : p.requires_grad, graphsage.parameters()))\n",
    "times = []\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "for batch in range(200):\n",
    "    batch_x = x[:100]\n",
    "    batch_y = y[:100]\n",
    "    x,y = shuffle(x,y)\n",
    "    optimizer.zero_grad()\n",
    "    loss = criterion(graphsage(batch_x),Variable(torch.LongTensor(batch_y)).squeeze())\n",
    "    loss.backward(retain_graph=True)\n",
    "    optimizer.step()\n",
    "    if batch %5 == 0:\n",
    "        print(batch, loss.data)\n",
    "\n",
    "        \n",
    "test_out = graphsage(xtest)\n",
    "ypred = test_out.data.numpy().argmax(axis=1)\n",
    "giveresults(ypred,ytest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 tensor(60.2128)\n",
      "5 tensor(37.6560)\n",
      "10 tensor(9.4221)\n",
      "15 tensor(5.4270)\n",
      "20 tensor(3.6977)\n",
      "25 tensor(5.7124)\n",
      "30 tensor(2.8556)\n",
      "35 tensor(2.8205)\n",
      "40 tensor(3.9305)\n",
      "45 tensor(2.2133)\n",
      "50 tensor(3.2538)\n",
      "55 tensor(2.7337)\n",
      "60 tensor(3.6590)\n",
      "65 tensor(1.7883)\n",
      "70 tensor(1.5695)\n",
      "75 tensor(2.0047)\n",
      "80 tensor(1.0618)\n",
      "85 tensor(1.7353)\n",
      "90 tensor(1.8304)\n",
      "95 tensor(1.5654)\n",
      "100 tensor(1.2039)\n",
      "105 tensor(0.7455)\n",
      "110 tensor(1.9424)\n",
      "115 tensor(1.6964)\n",
      "120 tensor(1.2944)\n",
      "125 tensor(1.6218)\n",
      "130 tensor(0.8732)\n",
      "135 tensor(1.3432)\n",
      "140 tensor(1.2868)\n",
      "145 tensor(2.0025)\n",
      "150 tensor(1.5719)\n",
      "155 tensor(0.9732)\n",
      "160 tensor(0.9870)\n",
      "165 tensor(1.5042)\n",
      "170 tensor(0.9378)\n",
      "175 tensor(1.4713)\n",
      "180 tensor(1.2767)\n",
      "185 tensor(0.6340)\n",
      "190 tensor(0.4814)\n",
      "195 tensor(1.0423)\n",
      "Accuracy  0.757\n",
      "Precision  0.678\n",
      "Recall  0.805\n",
      "F1 Score  0.736\n"
     ]
    }
   ],
   "source": [
    "agg1 = MeanAggregator(features,n2mat)\n",
    "enc1 = Encoder(features, 18, 11, ttg, agg1,n2mat)\n",
    "agg2 = MeanAggregator(enc1(nodes).t(), n2mat)\n",
    "enc2 = Encoder(enc1(nodes).t(), 11, 11, ttg, agg2,n2mat, base_model=enc1)\n",
    "\n",
    "graphsage = SupervisedGraphSage(enc2)\n",
    "\n",
    "optimizer = torch.optim.Adam(filter(lambda p : p.requires_grad, graphsage.parameters()))\n",
    "times = []\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "for batch in range(200):\n",
    "    batch_x = x[:100]\n",
    "    batch_y = y[:100]\n",
    "    x,y = shuffle(x,y)\n",
    "    optimizer.zero_grad()\n",
    "    loss = criterion(graphsage(batch_x),Variable(torch.LongTensor(batch_y)).squeeze())\n",
    "    loss.backward(retain_graph=True)\n",
    "    optimizer.step()\n",
    "    if batch %5 == 0:\n",
    "        print(batch, loss.data)\n",
    "\n",
    "        \n",
    "test_out = graphsage(xtest)\n",
    "ypred = test_out.data.numpy().argmax(axis=1)\n",
    "giveresults(ypred,ytest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 tensor(6.1066)\n",
      "5 tensor(2.6316)\n",
      "10 tensor(1.1648)\n",
      "15 tensor(1.2193)\n",
      "20 tensor(0.9194)\n",
      "25 tensor(0.3824)\n",
      "30 tensor(0.6241)\n",
      "35 tensor(0.6781)\n",
      "40 tensor(0.6215)\n",
      "45 tensor(0.4889)\n",
      "50 tensor(0.7198)\n",
      "55 tensor(0.7817)\n",
      "60 tensor(0.5965)\n",
      "65 tensor(0.5112)\n",
      "70 tensor(0.4656)\n",
      "75 tensor(0.3228)\n",
      "80 tensor(0.5370)\n",
      "85 tensor(0.4534)\n",
      "90 tensor(0.5918)\n",
      "95 tensor(0.5103)\n",
      "100 tensor(0.4160)\n",
      "105 tensor(0.4762)\n",
      "110 tensor(0.4587)\n",
      "115 tensor(0.4674)\n",
      "120 tensor(0.5009)\n",
      "125 tensor(0.5701)\n",
      "130 tensor(0.4908)\n",
      "135 tensor(0.4161)\n",
      "140 tensor(0.4078)\n",
      "145 tensor(0.4950)\n",
      "150 tensor(0.3838)\n",
      "155 tensor(0.3800)\n",
      "160 tensor(0.3538)\n",
      "165 tensor(0.6167)\n",
      "170 tensor(0.3738)\n",
      "175 tensor(0.4238)\n",
      "180 tensor(0.4169)\n",
      "185 tensor(0.4096)\n",
      "190 tensor(0.3117)\n",
      "195 tensor(0.2767)\n",
      "Accuracy  0.827\n",
      "Precision  0.829\n",
      "Recall  0.826\n",
      "F1 Score  0.827\n"
     ]
    }
   ],
   "source": [
    "agg1 = MeanAggregator(features,n2mat)\n",
    "enc1 = Encoder(features, 18, 19, ttg, agg1,n2mat)\n",
    "agg2 = MeanAggregator(enc1(nodes).t(), n2mat)\n",
    "enc2 = Encoder(enc1(nodes).t(), 19, 19, ttg, agg2,n2mat, base_model=enc1)\n",
    "\n",
    "graphsage = SupervisedGraphSage(enc2)\n",
    "\n",
    "optimizer = torch.optim.Adam(filter(lambda p : p.requires_grad, graphsage.parameters()))\n",
    "times = []\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "for batch in range(200):\n",
    "    batch_x = x[:100]\n",
    "    batch_y = y[:100]\n",
    "    x,y = shuffle(x,y)\n",
    "    optimizer.zero_grad()\n",
    "    loss = criterion(graphsage(batch_x),Variable(torch.LongTensor(batch_y)).squeeze())\n",
    "    loss.backward(retain_graph=True)\n",
    "    optimizer.step()\n",
    "    if batch %5 == 0:\n",
    "        print(batch, loss.data)\n",
    "\n",
    "        \n",
    "test_out = graphsage(xtest)\n",
    "ypred = test_out.data.numpy().argmax(axis=1)\n",
    "giveresults(ypred,ytest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 tensor(57.5669)\n",
      "5 tensor(22.6446)\n",
      "10 tensor(12.4797)\n",
      "15 tensor(6.3263)\n",
      "20 tensor(4.9281)\n",
      "25 tensor(0.7742)\n",
      "30 tensor(2.2404)\n",
      "35 tensor(2.2677)\n",
      "40 tensor(1.5048)\n",
      "45 tensor(0.8031)\n",
      "50 tensor(1.3173)\n",
      "55 tensor(0.9807)\n",
      "60 tensor(0.7349)\n",
      "65 tensor(1.0187)\n",
      "70 tensor(0.6818)\n",
      "75 tensor(0.9619)\n",
      "80 tensor(1.5718)\n",
      "85 tensor(0.7884)\n",
      "90 tensor(1.6423)\n",
      "95 tensor(0.7299)\n",
      "100 tensor(0.4386)\n",
      "105 tensor(0.8431)\n",
      "110 tensor(0.7416)\n",
      "115 tensor(0.6553)\n",
      "120 tensor(0.7065)\n",
      "125 tensor(0.6272)\n",
      "130 tensor(0.5377)\n",
      "135 tensor(0.6709)\n",
      "140 tensor(0.9400)\n",
      "145 tensor(0.4501)\n",
      "150 tensor(0.5273)\n",
      "155 tensor(0.5573)\n",
      "160 tensor(0.3784)\n",
      "165 tensor(0.6340)\n",
      "170 tensor(0.5781)\n",
      "175 tensor(0.5664)\n",
      "180 tensor(1.3726)\n",
      "185 tensor(0.4536)\n",
      "190 tensor(0.6067)\n",
      "195 tensor(0.4592)\n",
      "Accuracy  0.789\n",
      "Precision  0.828\n",
      "Recall  0.768\n",
      "F1 Score  0.797\n"
     ]
    }
   ],
   "source": [
    "agg1 = MeanAggregator(features,n2mat)\n",
    "enc1 = Encoder(features, 18, 20, ttg, agg1,n2mat)\n",
    "agg2 = MeanAggregator(enc1(nodes).t(), n2mat)\n",
    "enc2 = Encoder(enc1(nodes).t(), 20, 20, ttg, agg2,n2mat, base_model=enc1)\n",
    "\n",
    "graphsage = SupervisedGraphSage(enc2)\n",
    "\n",
    "optimizer = torch.optim.Adam(filter(lambda p : p.requires_grad, graphsage.parameters()))\n",
    "times = []\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "for batch in range(200):\n",
    "    batch_x = x[:100]\n",
    "    batch_y = y[:100]\n",
    "    x,y = shuffle(x,y)\n",
    "    optimizer.zero_grad()\n",
    "    loss = criterion(graphsage(batch_x),Variable(torch.LongTensor(batch_y)).squeeze())\n",
    "    loss.backward(retain_graph=True)\n",
    "    optimizer.step()\n",
    "    if batch %5 == 0:\n",
    "        print(batch, loss.data)\n",
    "\n",
    "        \n",
    "test_out = graphsage(xtest)\n",
    "ypred = test_out.data.numpy().argmax(axis=1)\n",
    "giveresults(ypred,ytest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 tensor(14.4615)\n",
      "5 tensor(3.8853)\n",
      "10 tensor(2.2624)\n",
      "15 tensor(1.9057)\n",
      "20 tensor(1.8163)\n",
      "25 tensor(3.5430)\n",
      "30 tensor(1.6745)\n",
      "35 tensor(1.6784)\n",
      "40 tensor(1.4359)\n",
      "45 tensor(1.1801)\n",
      "50 tensor(1.0388)\n",
      "55 tensor(1.0197)\n",
      "60 tensor(2.5836)\n",
      "65 tensor(0.8260)\n",
      "70 tensor(0.6559)\n",
      "75 tensor(1.3281)\n",
      "80 tensor(1.7722)\n",
      "85 tensor(0.6260)\n",
      "90 tensor(0.9001)\n",
      "95 tensor(1.1291)\n",
      "100 tensor(0.7057)\n",
      "105 tensor(0.4740)\n",
      "110 tensor(0.6175)\n",
      "115 tensor(1.0605)\n",
      "120 tensor(0.9118)\n",
      "125 tensor(1.1030)\n",
      "130 tensor(0.9446)\n",
      "135 tensor(1.4943)\n",
      "140 tensor(0.5717)\n",
      "145 tensor(0.8606)\n",
      "150 tensor(1.6501)\n",
      "155 tensor(0.8220)\n",
      "160 tensor(0.9668)\n",
      "165 tensor(0.5026)\n",
      "170 tensor(1.0481)\n",
      "175 tensor(0.9604)\n",
      "180 tensor(0.7535)\n",
      "185 tensor(0.4976)\n",
      "190 tensor(0.4716)\n",
      "195 tensor(0.5703)\n",
      "Accuracy  0.774\n",
      "Precision  0.684\n",
      "Recall  0.834\n",
      "F1 Score  0.752\n"
     ]
    }
   ],
   "source": [
    "agg1 = MeanAggregator(features,n2mat)\n",
    "enc1 = Encoder(features, 18, 50, ttg, agg1,n2mat)\n",
    "agg2 = MeanAggregator(enc1(nodes).t(), n2mat)\n",
    "enc2 = Encoder(enc1(nodes).t(), 50, 50, ttg, agg2,n2mat, base_model=enc1)\n",
    "\n",
    "graphsage = SupervisedGraphSage(enc2)\n",
    "\n",
    "optimizer = torch.optim.Adam(filter(lambda p : p.requires_grad, graphsage.parameters()))\n",
    "times = []\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "for batch in range(200):\n",
    "    batch_x = x[:100]\n",
    "    batch_y = y[:100]\n",
    "    x,y = shuffle(x,y)\n",
    "    optimizer.zero_grad()\n",
    "    loss = criterion(graphsage(batch_x),Variable(torch.LongTensor(batch_y)).squeeze())\n",
    "    loss.backward(retain_graph=True)\n",
    "    optimizer.step()\n",
    "    if batch %5 == 0:\n",
    "        print(batch, loss.data)\n",
    "\n",
    "        \n",
    "test_out = graphsage(xtest)\n",
    "ypred = test_out.data.numpy().argmax(axis=1)\n",
    "giveresults(ypred,ytest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 tensor(32.9190)\n",
      "5 tensor(10.2902)\n",
      "10 tensor(4.4885)\n",
      "15 tensor(2.1658)\n",
      "20 tensor(0.6366)\n",
      "25 tensor(1.6296)\n",
      "30 tensor(0.9962)\n",
      "35 tensor(0.7063)\n",
      "40 tensor(2.2302)\n",
      "45 tensor(0.6603)\n",
      "50 tensor(0.8182)\n",
      "55 tensor(0.8327)\n",
      "60 tensor(0.6313)\n",
      "65 tensor(0.9747)\n",
      "70 tensor(0.6925)\n",
      "75 tensor(0.6602)\n",
      "80 tensor(0.4182)\n",
      "85 tensor(0.6089)\n",
      "90 tensor(0.4959)\n",
      "95 tensor(0.6713)\n",
      "100 tensor(0.5984)\n",
      "105 tensor(0.4131)\n",
      "110 tensor(0.4514)\n",
      "115 tensor(0.4854)\n",
      "120 tensor(0.4895)\n",
      "125 tensor(0.4832)\n",
      "130 tensor(0.7894)\n",
      "135 tensor(0.5100)\n",
      "140 tensor(0.7463)\n",
      "145 tensor(0.3026)\n",
      "150 tensor(0.5753)\n",
      "155 tensor(0.3720)\n",
      "160 tensor(0.4754)\n",
      "165 tensor(0.3958)\n",
      "170 tensor(0.4785)\n",
      "175 tensor(0.4767)\n",
      "180 tensor(0.3513)\n",
      "185 tensor(0.4023)\n",
      "190 tensor(0.3148)\n",
      "195 tensor(0.4261)\n",
      "Accuracy  0.821\n",
      "Precision  0.778\n",
      "Recall  0.85\n",
      "F1 Score  0.813\n"
     ]
    }
   ],
   "source": [
    "agg1 = MeanAggregator(features,n2mat)\n",
    "enc1 = Encoder(features, 18, 100, ttg, agg1,n2mat)\n",
    "agg2 = MeanAggregator(enc1(nodes).t(), n2mat)\n",
    "enc2 = Encoder(enc1(nodes).t(), 100, 100, ttg, agg2,n2mat, base_model=enc1)\n",
    "\n",
    "graphsage = SupervisedGraphSage(enc2)\n",
    "\n",
    "optimizer = torch.optim.Adam(filter(lambda p : p.requires_grad, graphsage.parameters()))\n",
    "times = []\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "for batch in range(200):\n",
    "    batch_x = x[:100]\n",
    "    batch_y = y[:100]\n",
    "    x,y = shuffle(x,y)\n",
    "    optimizer.zero_grad()\n",
    "    loss = criterion(graphsage(batch_x),Variable(torch.LongTensor(batch_y)).squeeze())\n",
    "    loss.backward(retain_graph=True)\n",
    "    optimizer.step()\n",
    "    if batch %5 == 0:\n",
    "        print(batch, loss.data)\n",
    "\n",
    "        \n",
    "test_out = graphsage(xtest)\n",
    "ypred = test_out.data.numpy().argmax(axis=1)\n",
    "giveresults(ypred,ytest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 tensor(43.5609)\n",
      "5 tensor(8.1452)\n",
      "10 tensor(2.6511)\n",
      "15 tensor(2.9570)\n",
      "20 tensor(1.2538)\n",
      "25 tensor(0.9190)\n",
      "30 tensor(2.1377)\n",
      "35 tensor(1.0743)\n",
      "40 tensor(1.0297)\n",
      "45 tensor(0.8179)\n",
      "50 tensor(1.1411)\n",
      "55 tensor(1.3800)\n",
      "60 tensor(0.6207)\n",
      "65 tensor(0.8470)\n",
      "70 tensor(0.6330)\n",
      "75 tensor(0.6057)\n",
      "80 tensor(0.4245)\n",
      "85 tensor(0.8043)\n",
      "90 tensor(0.5482)\n",
      "95 tensor(0.7438)\n",
      "100 tensor(0.7053)\n",
      "105 tensor(0.8950)\n",
      "110 tensor(0.7068)\n",
      "115 tensor(0.5087)\n",
      "120 tensor(0.3072)\n",
      "125 tensor(0.5766)\n",
      "130 tensor(0.4090)\n",
      "135 tensor(0.2918)\n",
      "140 tensor(0.4522)\n",
      "145 tensor(0.3297)\n",
      "150 tensor(0.4041)\n",
      "155 tensor(0.3641)\n",
      "160 tensor(0.3352)\n",
      "165 tensor(0.3146)\n",
      "170 tensor(0.3617)\n",
      "175 tensor(0.3731)\n",
      "180 tensor(0.3673)\n",
      "185 tensor(0.4902)\n",
      "190 tensor(0.3299)\n",
      "195 tensor(0.4324)\n",
      "Accuracy  0.827\n",
      "Precision  0.831\n",
      "Recall  0.825\n",
      "F1 Score  0.828\n"
     ]
    }
   ],
   "source": [
    "agg1 = MeanAggregator(features,n2mat)\n",
    "enc1 = Encoder(features, 18, 200, ttg, agg1,n2mat)\n",
    "agg2 = MeanAggregator(enc1(nodes).t(), n2mat)\n",
    "enc2 = Encoder(enc1(nodes).t(), 200, 200, ttg, agg2,n2mat, base_model=enc1)\n",
    "\n",
    "graphsage = SupervisedGraphSage(enc2)\n",
    "\n",
    "optimizer = torch.optim.Adam(filter(lambda p : p.requires_grad, graphsage.parameters()))\n",
    "times = []\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "for batch in range(200):\n",
    "    batch_x = x[:100]\n",
    "    batch_y = y[:100]\n",
    "    x,y = shuffle(x,y)\n",
    "    optimizer.zero_grad()\n",
    "    loss = criterion(graphsage(batch_x),Variable(torch.LongTensor(batch_y)).squeeze())\n",
    "    loss.backward(retain_graph=True)\n",
    "    optimizer.step()\n",
    "    if batch %5 == 0:\n",
    "        print(batch, loss.data)\n",
    "\n",
    "        \n",
    "test_out = graphsage(xtest)\n",
    "ypred = test_out.data.numpy().argmax(axis=1)\n",
    "giveresults(ypred,ytest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 tensor(9.4583)\n",
      "5 tensor(3.1506)\n",
      "10 tensor(0.8428)\n",
      "15 tensor(1.0863)\n",
      "20 tensor(0.7788)\n",
      "25 tensor(0.5713)\n",
      "30 tensor(0.5374)\n",
      "35 tensor(0.5545)\n",
      "40 tensor(0.4626)\n",
      "45 tensor(0.4704)\n",
      "50 tensor(0.3696)\n",
      "55 tensor(0.3887)\n",
      "60 tensor(0.3847)\n",
      "65 tensor(0.4363)\n",
      "70 tensor(0.3797)\n",
      "75 tensor(0.3391)\n",
      "80 tensor(0.3500)\n",
      "85 tensor(0.4251)\n",
      "90 tensor(0.4280)\n",
      "95 tensor(0.3946)\n",
      "100 tensor(0.4747)\n",
      "105 tensor(0.4105)\n",
      "110 tensor(0.3686)\n",
      "115 tensor(0.3567)\n",
      "120 tensor(0.3820)\n",
      "125 tensor(0.3520)\n",
      "130 tensor(0.3531)\n",
      "135 tensor(0.3655)\n",
      "140 tensor(0.3870)\n",
      "145 tensor(0.3676)\n",
      "150 tensor(0.3689)\n",
      "155 tensor(0.3427)\n",
      "160 tensor(0.4912)\n",
      "165 tensor(0.3560)\n",
      "170 tensor(0.3372)\n",
      "175 tensor(0.4955)\n",
      "180 tensor(0.4041)\n",
      "185 tensor(0.4140)\n",
      "190 tensor(0.3305)\n",
      "195 tensor(0.3169)\n",
      "Accuracy  0.845\n",
      "Precision  0.829\n",
      "Recall  0.857\n",
      "F1 Score  0.842\n"
     ]
    }
   ],
   "source": [
    "agg1 = MeanAggregator(features,n2mat)\n",
    "enc1 = Encoder(features, 18, 500, ttg, agg1,n2mat)\n",
    "agg2 = MeanAggregator(enc1(nodes).t(), n2mat)\n",
    "enc2 = Encoder(enc1(nodes).t(), 500, 500, ttg, agg2,n2mat, base_model=enc1)\n",
    "\n",
    "graphsage = SupervisedGraphSage(enc2)\n",
    "\n",
    "optimizer = torch.optim.Adam(filter(lambda p : p.requires_grad, graphsage.parameters()))\n",
    "times = []\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "for batch in range(200):\n",
    "    batch_x = x[:500]\n",
    "    batch_y = y[:500]\n",
    "    x,y = shuffle(x,y)\n",
    "    optimizer.zero_grad()\n",
    "    loss = criterion(graphsage(batch_x),Variable(torch.LongTensor(batch_y)).squeeze())\n",
    "    loss.backward(retain_graph=True)\n",
    "    optimizer.step()\n",
    "    if batch %5 == 0:\n",
    "        print(batch, loss.data)\n",
    "\n",
    "        \n",
    "test_out = graphsage(xtest)\n",
    "ypred = test_out.data.numpy().argmax(axis=1)\n",
    "giveresults(ypred,ytest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
